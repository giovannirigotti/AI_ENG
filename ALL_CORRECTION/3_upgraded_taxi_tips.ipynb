{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f94a567-b156-49a0-ae8f-b1bb9a60145f",
   "metadata": {},
   "source": [
    "# Upgrade chicago Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fc891-fd45-4a9e-98f0-e8960a6f9755",
   "metadata": {},
   "source": [
    "In the lab session 2 you had to create component for a basic pipeline, now we will add preprocessing and model push to minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2a5df62-ec76-4c62-ae37-09096e4ba8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependancies\n",
    "import kfp as kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "import os\n",
    "from kfp.components import InputPath, OutputPath, create_component_from_func\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad666de3-3437-49e0-b411-1e6427fb6913",
   "metadata": {},
   "source": [
    "## 3.0 Recover a stable state for development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4772838-7c65-466c-b083-12eb0de77a88",
   "metadata": {},
   "source": [
    "### 3.0.1 Get the data locally to test components functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c21d7b4-e166-488e-b38f-a1c1f7158d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/aiengineercourse/Data_Pipeline_2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f95f131a-206f-4786-91d0-490898ecf687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./chicagodata’: File exists\n",
      "mkdir: cannot create directory ‘./data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./chicagodata\n",
    "!mkdir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb2d0b",
   "metadata": {},
   "source": [
    "### 3.0.1.1 Get data from opendata data.cityofchicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e904dcc-d03b-442e-9452-2e4eeb46d1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1087k    0 1087k    0     0   351k      0 --:--:--  0:00:03 --:--:--  351k\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset Taxi Trips as CSV\n",
    "!curl --get 'https://data.cityofchicago.org/resource/wrvz-psew.csv' \\\n",
    "  --data-urlencode '$limit=10000' \\\n",
    "  --data-urlencode '$where=trip_start_timestamp >= \"2023-01-01\" AND trip_start_timestamp < \"2023-02-01\"' \\\n",
    "  --data-urlencode '$select=tips,trip_start_timestamp,trip_seconds,trip_miles,pickup_community_area,pickup_centroid_latitude,pickup_centroid_longitude,dropoff_community_area,fare,tolls,extras,trip_total' \\\n",
    "  | tr -d '\"' > \"./chicagodata/trip.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fd867-ba61-456a-ae13-6a372143dcd7",
   "metadata": {},
   "source": [
    "### 3.0.1.2 Ensure parquet dataset is in Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97ffaf37-52d4-46b3-a0fd-544b660eded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=''#firstname-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02791463-732c-44a3-ac05-2aa8e21843f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a client with the access key and the secret key given\n",
    "client = Minio(\n",
    "    \"storage-api.course.aiengineer.codex-platform.com\",\n",
    "    access_key=os.getenv(\"MINIO-ACCESS-KEY\"),\n",
    "    secret_key=os.getenv(\"MINIO-SECRET-KEY\"),\n",
    "    secure=True,\n",
    "    http_client=urllib3.PoolManager(\n",
    "        \n",
    "        retries=urllib3.Retry(\n",
    "            total=5,\n",
    "            backoff_factor=0.2,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01344bb6-afdd-4280-b885-8c84f0c67c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Object: bucket_name: guillaume-etevenard object_name: b'datasets/chicago/trips.parquet' version_id: None last_modified: 2023-11-13 09:51:03.094000+00:00 etag: a8bb9b8e7ea668308e0ec481e21435c1 size: 138492 content_type: None is_dir: False metadata: None >\n"
     ]
    }
   ],
   "source": [
    "### use the api to list objects into the bucket\n",
    "objects = client.list_objects(bucket,prefix=\"datasets\",recursive=True)\n",
    "for obj in objects:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ebd2d-07b5-4f3f-84ee-28f2f50cdb20",
   "metadata": {},
   "source": [
    "### 3.0.1.3 If not, put it from local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b0df6fd-2cab-46dc-862b-f855c98ec0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a8bb9b8e7ea668308e0ec481e21435c1', None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import depandancies\n",
    "from io import BytesIO\n",
    "import pyarrow\n",
    "\n",
    "data = pd.read_csv(\"./chicagodata/trip.csv\",sep=\",\")\n",
    "\n",
    "### We will persist using \"parquet\" instead of csv for encoding/typing purpose\n",
    "### convert data to parquet using pandas (if you struggle with the parquet engine used by pandas, choose pyarrow)\n",
    "parquet_bytes=data.to_parquet(engine='auto')\n",
    "\n",
    "### Use BytesIO to wrap parquet into a bytes stream objetc\n",
    "parquet_buffer = BytesIO(parquet_bytes)\n",
    "\n",
    "path_minio=\"datasets/chicago/trips.parquet\"\n",
    "\n",
    "### put the parquet file\n",
    "### fill the params with the put_object documentation\n",
    "client.put_object(bucket,\n",
    "                   path_minio,\n",
    "                    data=parquet_buffer,\n",
    "                    length=len(parquet_bytes),\n",
    "                    content_type='application/parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985983f-9acd-4feb-b37e-c7dce15dcf22",
   "metadata": {},
   "source": [
    "## 3.1 From last session pipelines and components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38221231-a334-444c-a25b-b46bfe2dcb66",
   "metadata": {},
   "source": [
    "### 3.1.1 Cpmponents\n",
    "\n",
    "You have access to precompiled components to build the initial pipeline, you can find the yaml and python definitions in ./components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07293b2f-5030-4bce-a708-596ecc288afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_from_minio_op = components.load_component_from_file('components/get_data_from_minio.yaml')\n",
    "xgboost_predict_on_csv_op=components.load_component_from_file('components/xgb_predict.yaml')\n",
    "xgboost_train_on_csv_op=components.load_component_from_file('components/xgb_train_dbg.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40190ca9-5d51-4905-b56c-8a5d618b873d",
   "metadata": {},
   "source": [
    "Here is the base code of the chicago pipeline, using the 3 former components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6973c856-969e-4d2a-977b-9429c2d6a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### username is like the last sessions, firstname-lastname\n",
    "username = ''#firstname-name\n",
    "namespace=f'kubeflow-user-{username}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ca02e",
   "metadata": {},
   "source": [
    "### 3.1.2 Taxi Tips Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b73667c-3c71-497c-abc6-c3e9b6509e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='xgboost_chicago_base')\n",
    "def xgboost_pipeline(namespace=namespace):\n",
    "    import datetime\n",
    "    from kfp.onprem import use_k8s_secret\n",
    "    \n",
    "    bucket=''#firstname-name\n",
    "    \n",
    "    data = get_data_from_minio_op(\n",
    "        minio_path = 'datasets/chicago/trips.parquet',\n",
    "        bucket = bucket,\n",
    "    )\n",
    "    \n",
    "    ### this allows using real secret in a component\n",
    "    data.apply(\n",
    "        use_k8s_secret(\n",
    "            secret_name='minio-service-account',\n",
    "            k8s_secret_key_to_env={\n",
    "                'access_key':'MINIO_ACCESS_KEY',\n",
    "                'secret_key':'MINIO_SECRET_KEY'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Training and prediction on dataset in CSV format\n",
    "    model_trained_on_csv = xgboost_train_on_csv_op(\n",
    "        training_data=data.output,\n",
    "        label_column=0,\n",
    "        objective='reg:squarederror',\n",
    "        num_iterations=200,\n",
    "    ).set_memory_limit('1Gi').outputs\n",
    "    \n",
    "    xgboost_predict_on_csv_op(\n",
    "        data=data.output,\n",
    "        model=model_trained_on_csv['model'],\n",
    "        label_column=0,\n",
    "    ).set_memory_limit('1Gi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d218d547-e287-4555-8258-9f631d869b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### a token has been automatically provided in the KF_PIPELINES_SA_TOKEN_PATH variable. This token allow accès to only your namespace\n",
    "token_file = os.getenv(\"KF_PIPELINES_SA_TOKEN_PATH\")\n",
    "with open(token_file) as f:\n",
    "    token = f.readline()\n",
    "client = kfp.Client(host='http://ml-pipeline.kubeflow.svc.cluster.local:8888',\n",
    "               existing_token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "164b1140-7a3a-4ac3-b3a1-d5ef77c192bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a new experiment for this session runs\n",
    "EXPERIMENT_NAME = 'Aiengineer labs session3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d41e3c84-fc0f-4559-8a6b-d33a06663d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow.svc.cluster.local:8888/#/experiments/details/89690800-5cd6-408c-a196-d44afbb3a718\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow.svc.cluster.local:8888/#/runs/details/3ae94be4-5504-4c76-b955-f09a0f8c78d2\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID:  3ae94be4-5504-4c76-b955-f09a0f8c78d2\n"
     ]
    }
   ],
   "source": [
    "### submit the base pipeline\n",
    "run_id = client.create_run_from_pipeline_func(\n",
    "    pipeline_func = xgboost_pipeline, \n",
    "    namespace=namespace, \n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=f\"XGB_chicago_base{dt.datetime.today().isoformat()}\",\n",
    "    arguments={},\n",
    ").run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b631dbf-1215-40a7-a2e5-a2124df5c9bf",
   "metadata": {},
   "source": [
    "## 3.2 Upgrade the pipeline developping new components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc806fe9-8420-43dc-9f8f-554d454e6c97",
   "metadata": {},
   "source": [
    "### 3.2.1 Preprocessing component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc275f83",
   "metadata": {},
   "source": [
    "He will be responsible of \n",
    "- impute missing values on train/test\n",
    "- get rid of outliers\n",
    "- separate train/test from validation datam\n",
    "- Return 2 parquet datasets : train_test_set that will be used by train component and validation_set that will be used by predict component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "633ed030-f17a-4b45-8103-73abb5ef978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    input_data_path: InputPath('parquet'), \n",
    "    preprocess_train_test_data: OutputPath(),\n",
    "    preprocess_validation_data: OutputPath(),\n",
    "    label_column: int = 0,\n",
    "):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    # Missing values imputations with mean values\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    \n",
    "    ### load data ###\n",
    "    \n",
    "    df = pd.read_parquet(\n",
    "        input_data_path,\n",
    "    )\n",
    "    \n",
    "    ### autoclean data to allow only copatible types in features\n",
    "    numerics = ['int','float']\n",
    "    df = df.select_dtypes(include=numerics)\n",
    "\n",
    "    ### separate train_test from validation\n",
    "\n",
    "    # Create our imputer to replace missing values with the mean e.g.\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_df = imp.fit(df)\n",
    "\n",
    "    # Impute our data, then transform train_test dataset \n",
    "    df_imp = imp_df.transform(df)\n",
    "\n",
    "    # Instanciate isolation forest to get rid of outliers\n",
    "    isolate_forest = IsolationForest(n_jobs=-1, random_state=1)\n",
    "    isolate_forest.fit(df_imp)\n",
    "    isolate_predictions =isolate_forest.predict(df_imp)\n",
    "\n",
    "    ### clean dataset with results\n",
    "    df_isolated = df_imp[np.where(isolate_predictions == 1, True, False)]\n",
    "    \n",
    "    ### back to dataframe\n",
    "    dataset = pd.DataFrame(df_isolated,columns = df.columns)\n",
    "    \n",
    "    ### separate train_test from validation\n",
    "    train_test,validation_set = train_test_split(dataset, test_size=0.2)\n",
    "    \n",
    "    ### write to parquet\n",
    "    train_test.to_parquet(preprocess_train_test_data)\n",
    "    validation_set.to_parquet(preprocess_validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622866ef",
   "metadata": {},
   "source": [
    "#### test the preprocess component locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12edd55a-9d1e-4db1-857c-527184495791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tips                         6704\n",
      "trip_seconds                 6704\n",
      "trip_miles                   6704\n",
      "pickup_community_area        6704\n",
      "pickup_centroid_latitude     6704\n",
      "pickup_centroid_longitude    6704\n",
      "dropoff_community_area       6704\n",
      "fare                         6704\n",
      "tolls                        6704\n",
      "extras                       6704\n",
      "trip_total                   6704\n",
      "dtype: int64\n",
      "tips                         1677\n",
      "trip_seconds                 1677\n",
      "trip_miles                   1677\n",
      "pickup_community_area        1677\n",
      "pickup_centroid_latitude     1677\n",
      "pickup_centroid_longitude    1677\n",
      "dropoff_community_area       1677\n",
      "fare                         1677\n",
      "tolls                        1677\n",
      "extras                       1677\n",
      "trip_total                   1677\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### need parquet in input\n",
    "data = pd.read_csv(\"./chicagodata/trip.csv\",sep=\",\")\n",
    "data.to_parquet(\"./chicagodata/trip.parquet\")\n",
    "### define output targets\n",
    "train=\"./data/train_test.parquet\"\n",
    "val=\"./data/validation.parquet\"\n",
    "### execute the preprocess\n",
    "preprocess_data(\"./chicagodata/trip.parquet\",train,val)\n",
    "###verify the cut\n",
    "print(pd.read_parquet(train).count())\n",
    "print(pd.read_parquet(val).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192f11e-18e3-4fd8-b46e-2cf46d334a90",
   "metadata": {},
   "source": [
    "#### Build the preprocess component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88924ea4-e7b1-4de2-aeab-3f15a50eeb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Preprocess data(input_data: 'parquet', label_column: int = '0')>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_component_from_func(\n",
    "    preprocess_data,\n",
    "    output_component_file='components/preprocess_data.yaml',\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=[\n",
    "        'numpy==1.21.6',\n",
    "        'xgboost==1.1.1',\n",
    "        'pandas==1.0.5',\n",
    "        'tensorboardX==2.5.1',\n",
    "        'scikit-learn==1.0',\n",
    "        'pyarrow==10.0.1'\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96447aa-6745-430b-8bd3-07a7bfe455a8",
   "metadata": {},
   "source": [
    "### 3.2.2 Model export component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67cc346d-8065-4939-a44a-3e0d8145b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xgboost_model_bst(\n",
    "    bucket: str,\n",
    "    input_model_path: InputPath('XGBoostModel'),\n",
    "    minio_model_path:str\n",
    "):\n",
    "    '''Make predictions using a trained XGBoost model.\n",
    "    Args:\n",
    "        bucket: Bucket name used in Minio to store the model \n",
    "        model_path: Path for the trained model in binary XGBoost format.\n",
    "    '''\n",
    "    import xgboost\n",
    "    import urllib3\n",
    "    from minio import Minio\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # load model using input model_path\n",
    "    model = xgboost.Booster(model_file=input_model_path)\n",
    "\n",
    "    model_dir = \".\"\n",
    "    BST_FILE = \"model.bst\"\n",
    "    model_file = os.path.join((model_dir), BST_FILE)\n",
    "    model.save_model(model_file)\n",
    "\n",
    "    client = Minio(\n",
    "        \"storage-api.course.aiengineer.codex-platform.com\",\n",
    "        access_key=os.getenv(\"MINIO_ACCESS_KEY\"),\n",
    "        secret_key=os.getenv(\"MINIO_SECRET_KEY\"),\n",
    "        secure=True,\n",
    "        http_client=urllib3.PoolManager(\n",
    "\n",
    "            retries=urllib3.Retry(\n",
    "                total=5,\n",
    "                backoff_factor=0.2,\n",
    "                status_forcelist=[500, 502, 503, 504],\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ### define path where the object will be stored\n",
    "    minio_model_name = f'{minio_model_path}/{BST_FILE}'\n",
    "    ### put object\n",
    "    client.fput_object(bucket, minio_model_name, BST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4b07dc6-5cfb-4897-bfaf-7df09201a295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Save xgboost model bst(bucket: str, input_model: 'XGBoostModel', minio_model_path: str)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_component_from_func(\n",
    "    save_xgboost_model_bst,\n",
    "    output_component_file='components/save_xgboost_model_bst.yaml',\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=[\n",
    "        'numpy==1.21.6',\n",
    "        'minio==6.0.2',\n",
    "        'xgboost==1.1.1',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961e74d-6829-4d83-b2ca-80446ff2d8de",
   "metadata": {},
   "source": [
    "### 3.2.3 Upgraded pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434e703",
   "metadata": {},
   "source": [
    "![pipeline2](./images/pipeline2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ebabcb6f-1ff5-45bf-ae03-556dc5eac8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data_op =components.load_component_from_file('components/preprocess_data.yaml')\n",
    "save_xgboost_model_bst_op =components.load_component_from_file('components/save_xgboost_model_bst.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cf30cd9a-64dc-4fd6-be7f-d4b98dc58af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=''#firstname-lastname\n",
    "namespace=f'kubeflow-user-{user}'\n",
    "dsl.pipeline(name='xgboost_chicago_base')\n",
    "def xgboost_pipeline_upgraded(namespace=namespace):\n",
    "    import datetime\n",
    "    from kfp.onprem import use_k8s_secret\n",
    "    \n",
    "    bucket=''#firstname-lastname\n",
    "    \n",
    "    data = get_data_from_minio_op(\n",
    "        minio_path = 'datasets/chicago/trips.parquet',\n",
    "        bucket = bucket,\n",
    "    )\n",
    "    \n",
    "    data.apply(\n",
    "        use_k8s_secret(\n",
    "            secret_name='minio-service-account',\n",
    "            k8s_secret_key_to_env={\n",
    "                'access_key':'MINIO_ACCESS_KEY',\n",
    "                'secret_key':'MINIO_SECRET_KEY'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    preprocessed_data = preprocess_data_op(\n",
    "        input_data = data.output\n",
    "    ).set_memory_limit('1Gi')\n",
    "    \n",
    "    \n",
    "    # Training and prediction on dataset in CSV format\n",
    "    model_trained_on_csv = xgboost_train_on_csv_op(\n",
    "        training_data=preprocessed_data.outputs['preprocess_train_test_data'],\n",
    "        label_column=0,\n",
    "        objective='reg:squarederror',\n",
    "        num_iterations=200,\n",
    "    ).set_memory_limit('1Gi').outputs\n",
    "    \n",
    "    xgboost_predict_on_csv_op(\n",
    "        data=preprocessed_data.outputs['preprocess_validation_data'],\n",
    "        model=model_trained_on_csv['model'],\n",
    "        label_column=0,\n",
    "    ).set_memory_limit('1Gi')\n",
    "    \n",
    "    saved = save_xgboost_model_bst_op(\n",
    "        bucket=bucket,\n",
    "        input_model = model_trained_on_csv['model'],\n",
    "        minio_model_path ='models/frompipeline/xgboost/chicago'\n",
    "    ).set_memory_limit('1Gi')\n",
    "    \n",
    "    saved.apply(\n",
    "        use_k8s_secret(\n",
    "            secret_name='minio-service-account',\n",
    "            k8s_secret_key_to_env={\n",
    "                'access_key':'MINIO_ACCESS_KEY',\n",
    "                'secret_key':'MINIO_SECRET_KEY'\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37518d6f-b94b-4ff0-a0a0-a1e75e8ef2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow.svc.cluster.local:8888/#/experiments/details/89690800-5cd6-408c-a196-d44afbb3a718\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow.svc.cluster.local:8888/#/runs/details/f2cd5cb4-8c59-4342-9368-f4d3355923b6\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID:  f2cd5cb4-8c59-4342-9368-f4d3355923b6\n"
     ]
    }
   ],
   "source": [
    "### submit the base pipeline\n",
    "run_id = client.create_run_from_pipeline_func(\n",
    "    pipeline_func = xgboost_pipeline_upgraded, \n",
    "    namespace=namespace, \n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=f\"XGB_chicago_upgrade{dt.datetime.today().isoformat()}\",\n",
    "    arguments={},\n",
    ").run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970e61d-f0c9-4fa3-9502-1ebc82710ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1db6d0c0fb62fcd92812f526c45c77dc568410c92bb0ad7cc615a53ad33175c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
