# ML Governance

### Technical enablers around data and ML artifacts

On the last session we improve pipeline development and we see how to create a service from a model archive.

To get more and more industrial we will add governance on our process.

- First, we will learn how to register, explore and inspect datasets within DataHub data catalog  [0_get_data_using_catalog.ipynb](0_get_data_using_catalog.ipynb)



- Then , we will fuix the definitions of our features and push it to a global Feature store called [Feast](https://docs.feast.dev/g) [1_create_and_store_features.ipynb](1_create_and_store_features.ipynb)

- Finally we will create a basic model and explore MLFLOW model registry [2_train_features_and_store_model.ipynb](2_train_features_and_store_model.ipynb)


